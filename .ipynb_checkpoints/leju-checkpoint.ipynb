{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/youngtsai/house_crawling'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import selenium\n",
    "import random_user_agent\n",
    "\n",
    "from selenium.common.exceptions import TimeoutException, WebDriverException\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.proxy import Proxy, ProxyType \n",
    "\n",
    "from random_user_agent.user_agent import UserAgent\n",
    "from random_user_agent.params import SoftwareName, OperatingSystem\n",
    "\n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import json\n",
    "\n",
    "\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class leju_crawler:\n",
    "    def __init__(self):\n",
    "#         software_names = [SoftwareName.CHROME.value]\n",
    "#         operating_systems = [OperatingSystem.WINDOWS.value, OperatingSystem.LINUX.value]\n",
    "#         user_agent_rotator = UserAgent(\n",
    "#             software_names = software_names,\n",
    "#             operating_systems = operating_systems,\n",
    "#             limit = 100\n",
    "#         )\n",
    "\n",
    "#         self.user_agent = user_agent_rotator.get_random_user_agent()\n",
    "#         print(user_agent)\n",
    "\n",
    "        self.user_agent = 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.50 Safari/537.36'\n",
    "\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument('--incognito')\n",
    "        chrome_options.add_argument('headless')\n",
    "        chrome_options.add_argument('--no-sandbox')\n",
    "        chrome_options.add_argument('--window-size=1420,1080')\n",
    "        chrome_options.add_argument(\"--disable-gpu\")\n",
    "        # chrome_options.add_argument(f'user-agent={user_agent}')\n",
    "        # chrome_options.add_experimental_option(\"excludeSwitches\", ['enable-automation'])\n",
    "        # chrome_options.add_argument(\"--disable-blink-features\");\n",
    "        # chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\");\n",
    "        # driver = webdriver.Chrome(options=chrome_options)\n",
    "        executable_path=os.getcwd()+'/chromedriver_6'\n",
    "#         print(executable_path)\n",
    "\n",
    "        self.browser = webdriver.Chrome(executable_path=executable_path, options=chrome_options)\n",
    "    \n",
    "    def fetch_data(self, url):\n",
    "        browser = self.browser\n",
    "        browser.get(url)\n",
    "        sleep(10)\n",
    "        data_soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "#         print(data_soup)\n",
    "        browser.quit()\n",
    "        \n",
    "        return data_soup\n",
    "        \n",
    "    def get_title(self, data):\n",
    "        title = data.find('title').string\n",
    "        \n",
    "        return title\n",
    "        \n",
    "    def get_price_info(self, data):\n",
    "        avg_price = data.find('div', class_='avg_house_price_val').text\n",
    "        max_price = data.find('div', class_='max_house_price_val').text\n",
    "        min_price = data.find('div', class_='min_house_price_val').text\n",
    "        this_year_avg_price = data.find('div', class_='avg_date_house_price_val').text\n",
    "        \n",
    "        info = {\n",
    "            'avg_price': avg_price,\n",
    "            'max_price': max_price, \n",
    "            'min_price': min_price,\n",
    "            'this_year_avg_price': this_year_avg_price\n",
    "        }\n",
    "        \n",
    "        return info\n",
    "    \n",
    "    def get_basic_info(self, data):\n",
    "        building_title = data.find('article', class_='building_title').text\n",
    "        households = data.find('article', class_='households').text\n",
    "        house_year = data.find('article', class_='house_year').text\n",
    "        ttotal_floor = data.find('article', class_='ttotal_floor').text\n",
    "        elementary = data.find('article', class_='elementary').text\n",
    "        junior = data.find('article', class_='junior').text\n",
    "        developer1 = data.find('article', class_='developer1').text\n",
    "        \n",
    "        basic_info = {\n",
    "            'building_title': building_title,\n",
    "            'households': households,\n",
    "            'house_year': house_year,\n",
    "            'ttotal_floor': ttotal_floor,\n",
    "            'elementary': elementary,\n",
    "            'junior': junior,\n",
    "            'developer1': developer1,\n",
    "        }\n",
    "        \n",
    "        return basic_info\n",
    "        \n",
    "        \n",
    "    def get_sale_items(self, data):\n",
    "        items = data.find_all('div', class_='sales-item-box')\n",
    "        sale_items = []\n",
    "        for item in items:\n",
    "            floor = item.find('span').text\n",
    "            title = item.find('a').text\n",
    "            link = item.find('a')['href']\n",
    "            price = item.find_all('li')[1].text\n",
    "            area = item.find_all('li')[0].text\n",
    "            \n",
    "            data = {\n",
    "                'floor': floor,\n",
    "                'title': title,\n",
    "                'link': link,\n",
    "                'price': price,\n",
    "                'area': area,\n",
    "            }\n",
    "            \n",
    "            sale_items.append(data)\n",
    "            \n",
    "        return sale_items\n",
    "            \n",
    "        \n",
    "            \n",
    "        \n",
    "    def get_data_json(self, data):\n",
    "        title = self.get_title(data)\n",
    "        price_info = self.get_price_info(data)\n",
    "        basic_info =self.get_basic_info(data)\n",
    "        sale_items = self.get_sale_items(data)\n",
    "        \n",
    "        data_json = {\n",
    "            \"title\": title,\n",
    "            'price_info': price_info,\n",
    "            'basic_info': basic_info,\n",
    "            'sale_items': sale_items\n",
    "        }\n",
    "        \n",
    "        return data_json\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygsheets\n",
    "import os\n",
    "current_path = os.getcwd()\n",
    "\n",
    "class sheet_worker:\n",
    "    def get_hash_str(self,data):\n",
    "        hash_str = abs(hash(data)) % (10 ** 8)\n",
    "        return hash_str\n",
    "        \n",
    "    def get_sheet(self, sheet_key):\n",
    "        scopes = [\"https://spreadsheets.google.com/feeds\"]\n",
    "        credentials = ServiceAccountCredentials.from_json_keyfile_name(current_path+\"/cred.json\", scopes)\n",
    "        gss_client = gspread.authorize(credentials)\n",
    "        spreadsheet_key_path = sheet_key\n",
    "        sheet = gss_client.open_by_key(spreadsheet_key_path)\n",
    "        return sheet\n",
    "    \n",
    "    def data_to_sheet_value_list(self, data):\n",
    "        profile = json.loads(data)\n",
    "        title = profile['title']\n",
    "        price_info = profile['price_info']\n",
    "        basic_info = profile['basic_info']\n",
    "\n",
    "        sale_items = profile['sale_items']\n",
    "        sheet_value_list = []\n",
    "        for sale_item in sale_items:\n",
    "            floor = sale_item['floor']\n",
    "            sub_title = sale_item['title']\n",
    "            link = sale_item['link']\n",
    "            price = sale_item['price']\n",
    "            area = sale_item['area']\n",
    "\n",
    "            sheet_value = [\n",
    "                str(title),\n",
    "                str(price_info),\n",
    "                str(basic_info),\n",
    "                floor,\n",
    "                sub_title,\n",
    "                link,\n",
    "                price,\n",
    "                area\n",
    "            ]\n",
    "\n",
    "            sheet_value_str = \"\".join(sheet_value)\n",
    "            hash_str = self.get_hash_str(sheet_value_str)\n",
    "            sheet_value.append(hash_str)\n",
    "            sheet_value_list.append(sheet_value)\n",
    "            \n",
    "        return sheet_value_list\n",
    "        \n",
    "        \n",
    "    def run(self, data):\n",
    "        sheet_key = '15V1XD3p_mD8SSP_TQkY2PwYTM_FjOAXQXD1GuJcrpfI'\n",
    "        sheet = self.get_sheet(sheet_key)\n",
    "        sheet_bot = sheet.worksheet('bot')\n",
    "\n",
    "        profile_list = data['profile']\n",
    "        for profile in profile_list:\n",
    "            sheet_value = self.data_to_sheet_value(profile)\n",
    "            print(sheet_value_list)\n",
    "        \n",
    "        sheet_row_cnt = 2\n",
    "        for sheet_value in sheet_value_list:\n",
    "            sheet_bot.insert_row(sheet_value, sheet_row_cnt)\n",
    "            sheet_row_cnt +=1\n",
    "            \n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profile': ['{\"title\": \"麗軒珍寶-7筆交易紀錄，實價登錄平均成交價為52.33萬/坪  \", \"price_info\": {\"avg_price\": \"52.33萬/坪\", \"max_price\": \"56.16萬/坪\", \"min_price\": \"48.96萬/坪\", \"this_year_avg_price\": \"--萬/坪\"}, \"basic_info\": {\"building_title\": \"大同街50巷26號\", \"households\": \"32戶\", \"house_year\": \"19年\", \"ttotal_floor\": \"8\", \"elementary\": \"文聖國小(雙語)\", \"junior\": \"光復國中、江翠國中\", \"developer1\": \"珍寶事業\"}, \"sale_items\": [{\"floor\": \"6樓\", \"title\": \"自售～麗軒珍寶景觀3...\", \"link\": \"https://sale.591.com.tw/home/house/detail/2/8756933.html\", \"price\": \"總價2680萬\", \"area\": \"坪數47坪\"}, {\"floor\": \"2樓\", \"title\": \"江翠捷運珍寶三房\", \"link\": \"https://buy.yungching.com.tw/house/4587875\", \"price\": \"總價2298萬\", \"area\": \"坪數35.61坪\"}]}']}\n"
     ]
    }
   ],
   "source": [
    "url_list = [\n",
    "    \"https://www.leju.com.tw/page_search_result?oid=L37611690f7027\",\n",
    "]\n",
    "body = {'profile':[]}\n",
    "for url in url_list:\n",
    "    crawler = leju_crawler()\n",
    "    data = crawler.fetch_data(url)\n",
    "    data_json = crawler.get_data_json(data)\n",
    "#         data_json = json.loads(data_json)\n",
    "#         data_json = json.dumps(data_json, indent=4, sort_keys=True, ensure_ascii=False).encode('utf8')\n",
    "    data_json = json.dumps(data_json, ensure_ascii=False).encode('utf8')\n",
    "#         print(data_json.decode())\n",
    "    body['profile'].append(data_json.decode())\n",
    "    \n",
    "print(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['麗軒珍寶-7筆交易紀錄，實價登錄平均成交價為52.33萬/坪  ', \"{'avg_price': '52.33萬/坪', 'max_price': '56.16萬/坪', 'min_price': '48.96萬/坪', 'this_year_avg_price': '--萬/坪'}\", \"{'building_title': '大同街50巷26號', 'households': '32戶', 'house_year': '19年', 'ttotal_floor': '8', 'elementary': '文聖國小(雙語)', 'junior': '光復國中、江翠國中', 'developer1': '珍寶事業'}\", '2樓', '江翠捷運珍寶三房', 'https://buy.yungching.com.tw/house/4587875', '總價2298萬', '坪數35.61坪', 55442021]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sht_worker = sheet_worker()\n",
    "sht_worker.run(body)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item = data.find_all('div', class_='sales-item-box')[1]\n",
    "# # print(item)\n",
    "# item.find_all('li')[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
